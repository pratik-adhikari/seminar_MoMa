\begin{abstract}
Large language models (LLMs) have recently been adopted as high‑level planners for robotic agents. However, most existing work focuses either on navigation or manipulation in isolation and assumes a fully explored environment. The paper \emph{Language‑Grounded Dynamic Scene Graphs for Interactive Object Search with Mobile Manipulation} by Honerkamp \textit{et~al}. introduces MoMa‑LLM, an approach that uses a dynamically updated scene graph to ground an LLM in partially observable household environments. The proposed system formulates interactive object search as a \gls{pomdp} and constructs a two‑level scene graph consisting of rooms and objects. It computes a navigational graph from a \gls{bev} occupancy map using a generalized Voronoi diagram, segments it into rooms via a door‑based kernel density estimate and assigns objects to rooms through a distance‑weighted path formulation. High‑level actions such as \textit{navigate}, \textit{open} and \textit{explore} are mapped to low‑level policies and embedded in a structured language prompt that guides the LLM. To evaluate performance, the authors introduce a search efficiency curve and its area under the curve (AUC‑E) to capture success as a function of interaction cost. This seminar report critically analyses the problem formulation, algorithmic design and experimental results of MoMa‑LLM and discusses its contributions and limitations in the context of mobile manipulation.
\end{abstract}
