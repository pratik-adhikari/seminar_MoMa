\chapter{Introduction}
\label{ch:introduction}

Autonomous mobile manipulation robots promise to assist humans in daily life by performing long‑horizon tasks such as fetching objects, organising rooms or setting tables.  Realising this vision requires agents that can interpret high‑level instructions, explore unknown indoor environments, build semantic representations and manipulate articulated objects.  Most existing robotics pipelines treat navigation and manipulation separately and rely on a priori maps; moreover, they employ hand‑crafted task planners that operate on abstract symbolic representations.  Such assumptions break down in the dynamic and cluttered households for which mobile manipulators are intended.  Large language models (LLMs) have recently been adopted as high‑level planners due to their ability to reason over free‑form instructions, but naively integrating them into robotics has proven challenging: LLMs may hallucinate actions that violate physical constraints and often struggle to handle partial observability.

The paper \emph{Language‑Grounded Dynamic Scene Graphs for Interactive Object Search with Mobile Manipulation} by Honerkamp \textit{et~al}. proposes MoMa‑LLM, a system that addresses these issues by grounding an LLM in a structured, dynamically updated scene graph.  The problem considered is \emph{semantic interactive object search}: given a language goal such as “bring me the milk from the fridge”, the robot must search for the object in an unfamiliar apartment, open doors and drawers, and deliver the item.  This task is formulated as a \gls{pomdp} with a continuous state space and requires balancing exploration with interaction.  MoMa‑LLM constructs a two‑level scene graph from raw sensor data in real time, combines this representation with a high‑level object‑centric action space and embeds both into language prompts for the LLM.  The system thereby tightly couples reasoning, perception and control.

This report provides a critical analysis of MoMa‑LLM.  We first survey related work on interactive search, scene graph representations and language‑driven robotics.  We then summarise the theoretical contributions of the paper, including the mathematical formulation of the dynamic scene graph, the object‑to‑room assignment and the high‑level planning algorithm.  Finally, we discuss experimental results and evaluate the strengths and weaknesses of the approach before outlining future research directions.

For completeness we refer the reader to the original publication describing MoMa‑LLM\cite{Honerkamp2024} for further details.
