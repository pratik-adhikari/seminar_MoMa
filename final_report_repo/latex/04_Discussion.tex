\section{Discussion}
\label{sec:discussion}

\textbf{Strengths}
\begin{itemize}
    \item \textbf{Open-vocabulary reasoning:} Capable of handling novel room and object categories without retraining \citetip{ref1}{MoMa-LLM (Honerkamp et al., 2024)}.
    \item \textbf{Structured reasoning:} Using scene graphs as a bridge allows the LLM to reason effectively about geometry and topology \citetip{ref2}{Long-Horizon Exploration (Schmalstieg et al., 2023)}.
    \item \textbf{Robustness:} Demonstrated resilience to segmentation errors and real-world domain shifts \citetip{ref4}{MORE (Mohammadi et al., 2025)}.
\end{itemize}

\textbf{Limitations}
\begin{itemize}
    \item \textbf{Perception dependency:} Heavily relies on ground-truth or high-quality semantics; limited by "garbage-in/garbage-out" \citetip{ref5}{MoMa-LLM Project Page}.
    \item \textbf{Latency:} LLM queries dominate the runtime, and full graph re-computation scales poorly \citetip{ref9}{MoMa-LLM - RSS Workshop}.
    \item \textbf{Cost blindness:} High-level planning decouples reasoning from low-level execution costs \citetip{ref12}{MoMa-LLM - Scribd}.
\end{itemize}

\textbf{Reproducibility}
\begin{itemize}
    \item \textbf{Code availability:} The authors reference a project page, but specific release details for the full pipeline are limited \citetip{ref14}{MoMa-LLM - Emergent Mind}.
    \item \textbf{Missing details:} Real-world failure analysis is constrained by limited feedback modalities \citetip{ref16}{Inter-LLM - Abstract}.
\end{itemize}
